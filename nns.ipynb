{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exact Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPU code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T14:24:27.162987Z",
     "start_time": "2020-08-04T14:24:27.158027Z"
    }
   },
   "outputs": [],
   "source": [
    "def getnns_cpu(self):\n",
    "    if self.hp['metric'] != 'ip':\n",
    "        print('%s not supported.'%self.hp['metric'])\n",
    "        return \n",
    "    \n",
    "    self.initialize()\n",
    "    start = time.time()\n",
    "    for i in tqdm(range(0, self.num_query, self.batch_size)):\n",
    "        query_slice = self.hp['query'][i:i+self.batch_size]\n",
    "        prod = np.dot(query_slice, self.w)\n",
    "        self.indices[i:i+self.batch_size] = np.argsort(prod, axis=1)[:, -self.K:]\n",
    "        self.data[i:i+self.batch_size] = np.take_along_axis(prod, self.indices[i:i+self.batch_size], axis=1)\n",
    "    end = time.time()\n",
    "\n",
    "    print('Total time, time per point : %.2fs, %.4fms/pt'%(end-start, (end-start)*1000/self.num_query))\n",
    "    return self.getnns()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T08:33:16.924084Z",
     "start_time": "2020-08-20T08:33:16.916256Z"
    }
   },
   "outputs": [],
   "source": [
    "def getnns_gpu(self):\n",
    "    self.initialize()\n",
    "    with torch.no_grad():\n",
    "        w_gpu = torch.from_numpy(self.w).float().cuda()\n",
    "\n",
    "        start = time.time()\n",
    "        for i in tqdm(range(0, self.num_query, self.batch_size)):\n",
    "            query_slice_gpu = torch.from_numpy(self.hp['query'][i:i+self.batch_size]).float().cuda()\n",
    "            \n",
    "            prod_gpu = None\n",
    "            if self.hp['metric'] == 'ip':\n",
    "                prod_gpu = torch.matmul(query_slice_gpu, w_gpu)\n",
    "            elif self.hp['metric'] == 'euclid':\n",
    "                prod_gpu = torch.cdist(query_slice_gpu, w_gpu)\n",
    "                \n",
    "            batch_data_gpu, batch_indices_gpu = torch.topk(prod_gpu, k=self.K, sorted=True, largest=self.hp['sim'])\n",
    "            self.data[i:i+self.batch_size], self.indices[i:i+self.batch_size] = batch_data_gpu.cpu().numpy(), batch_indices_gpu.cpu().numpy()\n",
    "        end = time.time()\n",
    "\n",
    "        print('Total time, time per point : %.2fs, %.4f ms/pt'%(end-start, (end-start)*1000/self.num_query))\n",
    "        del w_gpu, query_slice_gpu, prod_gpu, batch_data_gpu, batch_indices_gpu\n",
    "        torch.cuda.empty_cache()\n",
    "        return self.getnns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T14:24:27.766093Z",
     "start_time": "2020-08-04T14:24:27.759912Z"
    }
   },
   "outputs": [],
   "source": [
    "def getnns_shorty_gpu(self, shorty):\n",
    "    if self.hp['metric'] != 'ip':\n",
    "        print('%s not supported.'%self.hp['metric'])\n",
    "        return \n",
    "    \n",
    "    self.K = shorty.shape[1]\n",
    "    self.initialize()\n",
    "    with torch.no_grad():\n",
    "        w_gpu = torch.from_numpy(self.hp['data']).float().cuda()\n",
    "\n",
    "        start = time.time()\n",
    "        for i in tqdm(range(0, self.num_query, self.batch_size)):\n",
    "            query_slice_gpu = torch.from_numpy(self.hp['query'][i:i+self.batch_size]).float().cuda()\n",
    "            batch_indices_gpu = torch.tensor(shorty[i:i+self.batch_size]).long().cuda()\n",
    "            \n",
    "            shorty_w_gpu = F.embedding(batch_indices_gpu, \n",
    "                                       w_gpu, \n",
    "                                       sparse=True)\n",
    "            batch_data_gpu = torch.matmul(query_slice_gpu.unsqueeze(1), shorty_w_gpu.permute(0, 2, 1)).squeeze()\n",
    "            \n",
    "            self.data[i:i+self.batch_size], self.indices[i:i+self.batch_size] = batch_data_gpu.cpu().numpy(), batch_indices_gpu.cpu().numpy()\n",
    "        end = time.time()\n",
    "\n",
    "        print('Total time, time per point : %.2fs, %.4f ms/pt'%(end-start, (end-start)*1000/self.num_query))\n",
    "        del w_gpu, query_slice_gpu, shorty_w_gpu, batch_data_gpu, batch_indices_gpu\n",
    "        torch.cuda.empty_cache()\n",
    "        return self.getnns()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapper class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T14:25:04.110775Z",
     "start_time": "2020-08-04T14:25:04.103990Z"
    }
   },
   "outputs": [],
   "source": [
    "class exact_search:\n",
    "    hp = {\n",
    "                'batch_size' : 512,\n",
    "                'score_mat' : '%s/score_mat_exact.bin'%(results_dir),\n",
    "                'data' : None,\n",
    "                'query' : None,\n",
    "                'K' : 10,\n",
    "                'sim' : True,\n",
    "                'metric' : 'ip'\n",
    "              }\n",
    "    getnns_gpu = getnns_gpu\n",
    "    getnns_cpu = getnns_cpu\n",
    "    getnns_shorty_gpu = getnns_shorty_gpu\n",
    "    num_query = None; num_base = None; batch_size = None; w = None; K = None; data = None; indices = None; indptr = None\n",
    "    \n",
    "    def __init__(self, hp):\n",
    "        for k, v in hp.items():\n",
    "            self.hp[k] = v\n",
    "        self.initialize()\n",
    "        \n",
    "    def initialize(self):\n",
    "        self.num_query = self.hp['query'].shape[0]\n",
    "        self.num_base = self.hp['data'].shape[0]\n",
    "        self.batch_size = self.hp['batch_size']\n",
    "        \n",
    "        if self.hp['metric'] == 'cosine':\n",
    "            self.hp['query'] = normalize(self.hp['query'], axis=1)\n",
    "            self.hp['data'] = normalize(self.hp['data'], axis=1)\n",
    "            self.hp['metric'] = 'ip'\n",
    "        \n",
    "        if self.hp['metric'] == 'ip':\n",
    "            self.w = self.hp['data'].transpose()\n",
    "            self.hp['sim'] = True\n",
    "        elif self.hp['metric'] == 'euclid':\n",
    "            self.w = self.hp['data']\n",
    "            self.hp['sim'] = False\n",
    "            \n",
    "        self.K = self.hp['K']\n",
    "        self.data = np.zeros((self.num_query, self.K))\n",
    "        self.indices = np.zeros((self.num_query, self.K), dtype=int)\n",
    "        self.indptr = range(0, self.data.shape[0]*self.data.shape[1]+1, self.data.shape[1])\n",
    "        \n",
    "    def getnns(self, save = False):\n",
    "        score_mat = csr_matrix((self.data.ravel(), self.indices.ravel(), self.indptr), (self.num_query, self.num_base))\n",
    "        if save: \n",
    "            sparse.save_npz(self.hp['score_mat'], score_mat)\n",
    "#         del self.data, self.indptr, self.indices\n",
    "        return score_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HNSW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_hnsw(self):\n",
    "    start = time.time()\n",
    "    self.index = nmslib.init(method='hnsw', space=self.hp['metric'])\n",
    "    self.index.addDataPointBatch(self.hp['data'])\n",
    "    self.index.createIndex({'M': self.hp['M'], 'indexThreadQty': self.hp['t'], 'efConstruction': self.hp['efC']}, print_progress=True)\n",
    "    end = time.time()\n",
    "    \n",
    "    self.train_time = (end-start)\n",
    "    print('Training time of ANNS datastructure = %f'%(self.train_time))\n",
    "    nmslib.saveIndex(self.index, self.hp['model_file'])\n",
    "    self.model_size = os.path.getsize(self.hp['model_file'])/1e6\n",
    "    print(\"Model size : %.2f MBytes\"%(self.model_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_hnsw(self):\n",
    "    self.index.setQueryTimeParams({'efSearch': self.hp['efS'], 'algoType': 'old'})\n",
    "    start = time.time()\n",
    "    nbrs = np.array(self.index.knnQueryBatch(self.hp['query'], k=self.hp['K'], num_threads = self.hp['t']), dtype=object)\n",
    "    end = time.time()\n",
    "    \n",
    "    self.search_time = end-start\n",
    "    print('Time taken to find approx nearest neighbors = %f'%(self.search_time))\n",
    "    \n",
    "    self.data = 1-nbrs[:, 1].ravel()\n",
    "    self.indptr = range(0, self.data.shape[0]+1, self.hp['K'])\n",
    "    self.indices = nbrs[:, 0].ravel()\n",
    "    del nbrs\n",
    "    return self.getnns()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapper class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class hnsw_search:\n",
    "    hp = {\n",
    "                'metric' : 'cosinesimil', \n",
    "                'M' : 50,\n",
    "                't' : 6,\n",
    "                'efC' : 100,\n",
    "                'model_file' : '%s/hnsw.bin'%(results_dir),\n",
    "                'data' : None,\n",
    "                'query' : None,\n",
    "                'efS' : 100,\n",
    "                'K' : 10,\n",
    "                'score_mat' : '%s/score_mat_hnsw.bin'%(results_dir),\n",
    "                'name' : ''\n",
    "              }\n",
    "    train = train_hnsw\n",
    "    search = search_hnsw\n",
    "    data = None; indices = None; indptr = None; index = None; num_query = None; num_base = None; total_base = None\n",
    "    keep_data = None; remap = None; remap_inv = None\n",
    "    train_time = None; search_time = None; model_size = None\n",
    "    \n",
    "    def __init__(self, hp):\n",
    "        for k, v in hp.items():\n",
    "            self.hp[k] = v\n",
    "        self.hp['model_file'] = '%s/hnsw_%s_%d_%d.bin'%(results_dir, self.hp['name'], self.hp['efC'], self.hp['M'])\n",
    "        self.total_base = self.hp['data'].shape[0]\n",
    "        self.preprocess()\n",
    "        \n",
    "    def preprocess(self):\n",
    "        if self.hp['metric'] == 'cosinesimil':\n",
    "            norms = np.linalg.norm(self.hp['data'], axis=1)\n",
    "            self.keep_data = np.where(abs(norms-1) < 0.05)[0]\n",
    "            del norms\n",
    "        else:\n",
    "            self.keep_data = np.arange(self.total_base)\n",
    "        print('Keeping %d/%d base points after preprocess'%(self.keep_data.shape[0], self.total_base))\n",
    "        \n",
    "        self.remap = np.vectorize({i : v for i, v in enumerate(self.keep_data)}.get)\n",
    "        self.remap_inv = np.vectorize({v : i for i, v in enumerate(self.keep_data)}.get)\n",
    "        self.hp['data'] = self.hp['data'][self.keep_data]\n",
    "        \n",
    "    def getnns(self):\n",
    "        score_mat = csr_matrix((self.data.ravel().astype(float), self.remap(self.indices.ravel().astype(int)), self.indptr), (self.hp['query'].shape[0], self.total_base))\n",
    "#         del self.data, self.indptr, self.indices\n",
    "        return score_mat\n",
    "    \n",
    "    def load_index(self, filename = None):\n",
    "        if filename is None: filename = self.hp['model_file']\n",
    "        self.index = nmslib.init(method='hnsw', space=self.hp['metric'])\n",
    "        nmslib.loadIndex(self.index, filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
